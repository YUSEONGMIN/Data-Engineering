{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7a56c7",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "- 모델명 : xxxxx-seg\n",
    "\n",
    "### 모델로딩 및 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42ecf08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T14:25:58.905615Z",
     "start_time": "2023-11-08T14:25:58.888889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977e60fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T14:17:56.247536Z",
     "start_time": "2023-11-08T14:17:55.617398Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8m-seg.pt to 'models\\yolov8m-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 52.4M/52.4M [02:02<00:00, 449kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 persons, 10 cars, 1: 640x640 4 persons, 1 bus, 1 tie, 4944.8ms\n",
      "Speed: 15.6ms preprocess, 2472.4ms inference, 70.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\segment\\predict\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict\\labels\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models/yolov8m-seg.pt'\n",
    "file_path = r'02_test_image_seg/beatles.jpg'\n",
    "file_path = [r'02_test_image_seg/beatles.jpg', '02_test_image_seg/bus.jpg']\n",
    "\n",
    "model_seg = YOLO(model_path)\n",
    "results = model_seg(file_path, save=True, save_txt=True, line_width=1)\n",
    "# results의 타입: List => 조회 이미지 개수별로 Results를 리스트에 묶어 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d66ad78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T14:17:56.829207Z",
     "start_time": "2023-11-08T14:17:56.824207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, list, ultralytics.engine.results.Results)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results), type(results), type(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7c5f3",
   "metadata": {},
   "source": [
    "## Segmentation 추론결과 조회\n",
    "- segmentation 추론 결과는 Boxes를 이용해 추론한 bounding box의 결과와 Masks를 이용해 분할된 mask 정보를 조회한다.\n",
    "- **ultralytics.yolo.engine.results.Masks**\n",
    "    - Segmentation 의 결과 type\n",
    "    - Results.masks 로 조회한다.\n",
    "    - 주요 속성, 메소드\n",
    "        - shape: [object 개수, height, width]\n",
    "            - height, width: mask image size\n",
    "        - data: 결과 Tensor(3차원 배열) 반환. `0: 배경, 1: 물체` 를 원소로 가지는 결과 Tensor를 반환한다.\n",
    "            - 픽셀별로 물체 인지 아닌 지를 표현하는 tensor를 반환\n",
    "        - xy, xyn : mask의 bounding 좌표(경계선 좌표)를 물체별로 list에 담아서 반환한다.\n",
    "            - 물체의 외곽선을 그리는 좌표들을 반환\n",
    "            - xy: 실제 좌표, xyn: 이미지의 width/height 대비 비율\n",
    "- **ultralytics.yolo.engine.results.Boxes**\n",
    "     - Results.boxes로 조회\n",
    "    - 주요 속성\n",
    "        - shape: 결과 shape. (찾은 물체개수, 6)\n",
    "        - boxes\n",
    "            - 6: 좌상단 x, 좌상단 y, 우하단 x, 우하단 y, confidence score, label\n",
    "        - xyxy\n",
    "            - bounding box의 `좌상단 x, 좌상단 y, 우하단 x, 우하단 y` 좌표 반환\n",
    "        - xyxyn\n",
    "            - xyxy를 이미지 대비 비율로 반환\n",
    "        - xywh\n",
    "            - bounding box의 `center x, center y, 너비, 높이` 를 반환\n",
    "        - xywhn\n",
    "            - xywh를 이미지 대비 비율로 반환\n",
    "        - cls: 찾은 물체의 label\n",
    "        - conf: cls에 대한 confidence score (그 물체일 확률)\n",
    "        - boxes\n",
    "            - `x, y, x, y, conf, cls` tensor를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "febc8939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T14:18:01.926291Z",
     "start_time": "2023-11-08T14:18:01.921291Z"
    }
   },
   "outputs": [],
   "source": [
    "# 첫번째이미지 추론결과\n",
    "result = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156a7135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T15:05:36.578030Z",
     "start_time": "2023-11-08T15:05:30.966902Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imshow('result', result.plot())\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f259f595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T14:18:02.587748Z",
     "start_time": "2023-11-08T14:18:02.568900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "## bbox 추론 결과들.\n",
    "boxes = result.boxes\n",
    "print(boxes.xyxy.shape)\n",
    "print(boxes.cls.shape)\n",
    "print(boxes.conf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16b37ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T14:18:24.869495Z",
     "start_time": "2023-11-08T14:18:24.865919Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ultralytics.engine.results.Masks'>\n"
     ]
    }
   ],
   "source": [
    "## segmentation 추론 결과\n",
    "masks = result.masks\n",
    "print(type(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13be783b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T15:12:24.401270Z",
     "start_time": "2023-11-08T15:12:24.384315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 <class 'list'> (374, 2)\n"
     ]
    }
   ],
   "source": [
    "print(len(masks.xy), type(masks.xy), masks.xy[0].shape)  # masks.xy[0]: 첫번째 instance. (point개수, 2-xy좌표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a8a093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T15:12:26.746597Z",
     "start_time": "2023-11-08T15:12:26.743597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 <class 'list'> (374, 2)\n"
     ]
    }
   ],
   "source": [
    "print(len(masks.xyn), type(masks.xyn), masks.xyn[0].shape)  # masks.xyn[0]: 첫번째 이미지. (point개수, 2) - width, height 대비 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487ed738",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T14:42:26.383067Z",
     "start_time": "2023-11-08T14:42:26.372037Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.zeros(result.orig_shape)\n",
    "\n",
    "idx = masks.xy[0].astype('int')\n",
    "y, x = idx[:,0], idx[:,1]   # y, x 좌표 나누기\n",
    "a[x, y] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db4d398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T14:42:27.016047Z",
     "start_time": "2023-11-08T14:42:26.907791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2611db0b280>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb64a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T15:16:11.070767Z",
     "start_time": "2023-11-08T15:16:11.037803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ultralytics.engine.results.Masks'> (374, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (298, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (357, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (315, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (95, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (12, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (24, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (29, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (26, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (60, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (10, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (11, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (11, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (21, 2)\n",
      "<class 'ultralytics.engine.results.Masks'> (28, 2)\n"
     ]
    }
   ],
   "source": [
    "# masks -> iterable\n",
    "for m in masks:\n",
    "    print(type(m), m.xy[0].shape)  #### 개별 object 조회결과를 가진 Masks 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f86cb51a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T17:06:29.675667Z",
     "start_time": "2023-11-08T17:06:27.137575Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Playdata\\Downloads\\Playdata_\\08_computervision\\실습\\02_test_image_seg\\bus.jpg: 640x480 4 persons, 1 bus, 1 tie, 1645.6ms\n",
      "Speed: 0.0ms preprocess, 1645.6ms inference, 31.2ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "#### xy 를 이용해 찾은 대상 물체 경계 그리기.\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 모델 생성\n",
    "model = YOLO(\"models/yolov8m-seg.pt\")\n",
    "# 추론\n",
    "result = model(\"02_test_image_seg/bus.jpg\")[0]\n",
    "masks = result.masks\n",
    "\n",
    "# 원본 이미지의 shape\n",
    "shape = result.orig_shape\n",
    "\n",
    "# 결과를 그릴 배열 - 원본이미지와 동일한 크기의 배열 생성\n",
    "arr = np.zeros(shape, dtype='uint8')  # 엣지 형식으로 선만 그릴 것\n",
    "instance_mask = np.zeros(shape, dtype=\"uint8\")  # 물체만 추출하기 위한 mask\n",
    "background_mask = np.full(shape, fill_value=255, dtype='uint8')  # 배경을 선택하기 위한 mask => blur 시킬 것.\n",
    "\n",
    "# 찾은 instance들의 경계 좌표 조회들\n",
    "xy_list = masks.xy  # 리스트: object 개수 (전체 object들에 대한 segment 결과)\n",
    "\n",
    "############# 사람만 따기\n",
    "for i in range(len(masks)):\n",
    "    if result.boxes[i].cls.item()==0: # class가 Person이면 (coco dataset에서 0: Person)\n",
    "        coords = xy_list[i].astype('int32')\n",
    "        arr = cv2.polylines(arr, [coords], isClosed=True, color=(255,255,255), thickness=2) # 선그리기\n",
    "        cv2.fillPoly(instance_mask, [coords], 255)                                          # 선 안쪽을 255로 채우기\n",
    "        cv2.fillPoly(background_mask, [coords], 0)                                          # 선 안쪽을 0으로 채우기\n",
    "\n",
    "        result_img = cv2.add(result.orig_img, # 원본 이미지 배열\n",
    "                             cv2.cvtColor(instance_mask, cv2.COLOR_GRAY2BGR) # 대상\n",
    "                            )\n",
    "        # cv2.add(배열1, 배열2) 배열1(uint8) + 배열2(uint8): 결과가 0 ~ 255 범위 밖이면 0, 255에 맞춘다. -> satu\n",
    "\n",
    "cv2.imshow(\"frame1\", arr)\n",
    "# cv2.waitKey()\n",
    "cv2.imshow(\"frame2\", instance_mask)\n",
    "# cv2.waitKey()\n",
    "cv2.imshow(\"frame3\", background_mask)\n",
    "# cv2.waitKey()\n",
    "cv2.imshow(\"frame4\", result_img)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7003ac18",
   "metadata": {},
   "source": [
    "# custom dataset training\n",
    "\n",
    "- custom dataset training은 object detection과 동일\n",
    "- custom dataset: https://universe.roboflow.com/angelo-maglasang-vuuq3/crack_flip_rotate/dataset/1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb1bc55",
   "metadata": {},
   "source": [
    "1. labeling\n",
    "    - 이미지 파일당 한개의 txt\n",
    "    - 한줄에 하나의 instance에 대한 설정. \n",
    "    ```\n",
    "    label x1 y1 x2 y2 .....  # x,y가 polygon 의 좌표\n",
    "    ```\n",
    "2. 학습관련 설정\n",
    "    - yaml 파일\n",
    "        - train: train set의 경로\n",
    "        - val: validation set의 경로\n",
    "        - test: test set의 경로\n",
    "        - nc: 클래스개수\n",
    "        - names: [클래스 이름]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b870bd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.14 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.13 🚀 Python-3.10.13 torch-2.2.0+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=models/yolov8n-seg.pt, data=C:/Users/Playdata/Downloads/Playdata_/08_computervision/실습/crack_flip_rotate.v1i.yolov8/data.yaml, epochs=100, time=None, patience=30, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\segment\\train3\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Playdata\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 755k/755k [00:05<00:00, 151kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Playdata\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3263811 parameters, 3263795 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mWARNING ⚠️ TensorBoard not initialized correctly, not logging this run. runs\\segment\\train3 is not a directory\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Playdata\\Downloads\\Playdata_\\08_computervision\\실습\\crack_flip_rotate.v1i.yolov8\\train\\labels.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Playdata\\Downloads\\Playdata_\\08_computervision\\실습\\crack_flip_rotate.v1i.yolov8\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Playdata\\Downloads\\Playdata_\\08_computervision\\실습\\crack_flip_rotate.v1i.yolov8\\valid\\labels...\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Playdata\\Downloads\\Playdata_\\08_computervision\\실습\\crack_flip_rotate.v1i.yolov8\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\segment\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\segment\\train3\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100         0G      1.937      3.596      3.226      1.765         67        640:  32%|███▏      | 6/19 [05:59<\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ft_model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/yolov8n-seg.pt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# pretrained 모델의 경로 => fine tuning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mft_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/Playdata/Downloads/Playdata_/08_computervision/실습/crack_flip_rotate.v1i.yolov8/data.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 데이터셋 설정파일\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default: 16\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# default: 640\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 조기종료 조건. \u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\ultralytics\\engine\\model.py:601\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 601\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\ultralytics\\engine\\trainer.py:208\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\ultralytics\\engine\\trainer.py:384\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    380\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    381\u001b[0m     )\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ft_model = YOLO('models/yolov8n-seg.pt') # pretrained 모델의 경로 => fine tuning\n",
    "ft_model.train(data='C:/Users/Playdata/Downloads/Playdata_/08_computervision/실습/crack_flip_rotate.v1i.yolov8/data.yaml', # 데이터셋 설정파일\n",
    "               epochs=100, \n",
    "               batch=32,  # default: 16\n",
    "               imgsz=640, # default: 640\n",
    "               patience=30, # 조기종료 조건. \n",
    "               optimizer='Adam'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "006122a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02_test_image_seg\\\\crack0.jpg',\n",
       " '02_test_image_seg\\\\crack1.jpg',\n",
       " '02_test_image_seg\\\\crack2.jpg',\n",
       " '02_test_image_seg\\\\crack3.jpg',\n",
       " '02_test_image_seg\\\\crack4.jpg',\n",
       " '02_test_image_seg\\\\crack5.jpg',\n",
       " '02_test_image_seg\\\\crack6.jpg',\n",
       " '02_test_image_seg\\\\crack7.jpg',\n",
       " '02_test_image_seg\\\\crack8.jpg',\n",
       " '02_test_image_seg\\\\crack9.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### 추론\n",
    "\n",
    "from glob import glob\n",
    "from ultralytics import YOLO\n",
    "best_model_path = 'crack_model/best.pt'\n",
    "image_files_path = glob('02_test_image_seg/crack*.jpg')\n",
    "image_files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76203567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 crack, 1: 640x640 1 crack, 2: 640x640 1 crack, 3: 640x640 2 cracks, 4: 640x640 1 crack, 5: 640x640 2 cracks, 6: 640x640 1 crack, 7: 640x640 4 cracks, 8: 640x640 2 cracks, 9: 640x640 1 crack, 4861.6ms\n",
      "Speed: 9.5ms preprocess, 486.2ms inference, 14.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\segment\\predict2\u001b[0m\n",
      "10 labels saved to runs\\segment\\predict2\\labels\n"
     ]
    }
   ],
   "source": [
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "results = best_model(image_files_path, save=True, save_txt=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d6bb26803bcea62f49e4c67963aa289be587a14c784102c9499967ce94407a08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
